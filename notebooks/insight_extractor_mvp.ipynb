{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf390f0c-0c4f-48e4-bc52-743f59d0472e",
   "metadata": {},
   "source": [
    "Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa84140c-facf-4d36-b760-bd88a3e4d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from typing import List, Optional\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"Environment ready\")\n",
    "else:\n",
    "    print(\"API key not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400f757-a3fe-4405-bc08-52aec745b96a",
   "metadata": {},
   "source": [
    "Load Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c88956-242e-4a52-a327-34b6aa3a5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research guidelines loaded\n",
      "   Frameworks: ['jobs_to_be_done', 'continuous_discovery', 'mom_test', 'mental_models']\n"
     ]
    }
   ],
   "source": [
    "with open('config/research_guidelines.yaml', 'r') as f:\n",
    "    guidelines = yaml.safe_load(f)\n",
    "\n",
    "print(\"research guidelines loaded\")\n",
    "print(f\"   Frameworks: {list(guidelines['frameworks'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c15bab-e032-4822-b8ee-0b9f304b42ec",
   "metadata": {},
   "source": [
    "Privacy & PII Removal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e96a345-1cca-4dc8-8b29-b61c4fd59f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy functions ready\n"
     ]
    }
   ],
   "source": [
    "def enforce_pii_removal(text: str, privacy_rules: dict) -> str:\n",
    "    \"\"\"Hard-enforced PII removal via pre-defined configurations\"\"\"\n",
    "    if not privacy_rules['pii_removal']['enabled']:\n",
    "        return text\n",
    "    \n",
    "    patterns = privacy_rules['pii_removal']['patterns']\n",
    "    replacements = privacy_rules['pii_removal']['replacement_tokens']\n",
    "    \n",
    "    text = re.sub(patterns['api_token'], replacements['api_token'], text)\n",
    "    text = re.sub(patterns['iban'], replacements['iban'], text)\n",
    "    text = re.sub(patterns['email'], replacements['email'], text, flags=re.IGNORECASE)\n",
    "    text = re.sub(patterns['phone'], replacements['phone'], text)\n",
    "    text = re.sub(patterns['employee_id'], replacements['employee_id'], text, flags=re.IGNORECASE)\n",
    "    text = re.sub(patterns['names'], replacements['names'], text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def validate_no_pii(insights, privacy_rules):\n",
    "    \"\"\"Validate no PII in output\"\"\"\n",
    "    all_text = insights.model_dump_json()\n",
    "    patterns = privacy_rules['pii_removal']['patterns']\n",
    "    \n",
    "    issues = []\n",
    "    if re.search(patterns['email'], all_text):\n",
    "        issues.append(\"EMAIL detected\")\n",
    "    if re.search(patterns['phone'], all_text):\n",
    "        issues.append(\"PHONE detected\")\n",
    "    if re.search(patterns['employee_id'], all_text):\n",
    "        issues.append(\"ID detected\")\n",
    "    \n",
    "    if issues:\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "        raise ValueError(\"PII VALIDATION FAILED\")\n",
    "    return True\n",
    "\n",
    "def audit_pii_in_transcript(text: str, privacy_rules: dict):\n",
    "    \"\"\"Count PII found in transcript\"\"\"\n",
    "    patterns = privacy_rules['pii_removal']['patterns']\n",
    "    \n",
    "    findings = {\n",
    "        'Emails': len(re.findall(patterns['email'], text)),\n",
    "        'Phone Numbers': len(re.findall(patterns['phone'], text)),\n",
    "        'Employee IDs': len(re.findall(patterns['employee_id'], text)),\n",
    "        'Names': len(re.findall(patterns['names'], text)),\n",
    "        'IBANs': len(re.findall(patterns['iban'], text)),\n",
    "        'API Tokens': len(re.findall(patterns['api_token'], text))\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPII Detection Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    for pii_type, count in findings.items():\n",
    "        print(f\"{pii_type:20} {count:>5}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"{'TOTAL':20} {sum(findings.values()):>5}\")\n",
    "\n",
    "print(\"Privacy functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e217a-83a1-4d4d-b79a-2e643d233b4d",
   "metadata": {},
   "source": [
    "Pydantic Models (Data structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d655f114-4414-45d3-a56d-be1019e4fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data models defined\n"
     ]
    }
   ],
   "source": [
    "class PainPoint(BaseModel):\n",
    "    description: str = Field(description=\"What's not working for the user\")\n",
    "    impact: str = Field(description=\"Time lost, extra work, costs, uncertainty\")\n",
    "    quote: str = Field(description=\"User's exact words\")\n",
    "\n",
    "class JobToBeDone(BaseModel):\n",
    "    functional_job: str = Field(description=\"What task are they trying to complete?\")\n",
    "    emotional_job: str = Field(description=\"How do they want to feel?\")\n",
    "    context: str = Field(description=\"When/where does this happen?\")\n",
    "    quote: str\n",
    "\n",
    "class Workaround(BaseModel):\n",
    "    what_they_do: str = Field(description=\"The workaround they've created\")\n",
    "    why_needed: str = Field(description=\"What problem does this solve?\")\n",
    "    cost: str = Field(description=\"Time/effort this workaround takes\")\n",
    "    quote: str\n",
    "\n",
    "class DesiredOutcome(BaseModel):\n",
    "    outcome: str = Field(description=\"What do they really want?\")\n",
    "    current_gap: str = Field(description=\"Why can't they achieve this now?\")\n",
    "    quote: str\n",
    "\n",
    "class BehavioralSignal(BaseModel):\n",
    "    observation: str = Field(description=\"What did they say/do that was revealing?\")\n",
    "    what_it_reveals: str = Field(description=\"The underlying need or belief\")\n",
    "    quote: str\n",
    "\n",
    "class MentalModel(BaseModel):\n",
    "    description: str = Field(description=\"How they think about or categorize something\")\n",
    "    metaphor_or_analogy: Optional[str] = Field(default=None)\n",
    "    mismatch_with_reality: Optional[str] = Field(default=None)\n",
    "    quote: str\n",
    "\n",
    "class InterviewInsights(BaseModel):\n",
    "    pain_points: List[PainPoint] = []  # ← Added default\n",
    "    jobs_to_be_done: List[JobToBeDone] = []  # ← Added default\n",
    "    workarounds: List[Workaround] = []  # ← Added default\n",
    "    desired_outcomes: List[DesiredOutcome] = []  # ← Added default\n",
    "    behavioral_signals: List[BehavioralSignal] = []  # ← Added default\n",
    "    mental_models: List[MentalModel] = []  # ← Added default\n",
    "\n",
    "print(\"Data models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122faac-cc0b-4443-9885-4783d28e88a9",
   "metadata": {},
   "source": [
    "Build system prompt and create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48287d24-f633-4909-8008-d88417d9eed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created with frameworks from research guidelines\n"
     ]
    }
   ],
   "source": [
    "def build_system_prompt(guidelines):\n",
    "    prompt = \"You are an expert product researcher.\\n\\n\"\n",
    "    prompt += \"APPLY THESE FRAMEWORKS:\\n\\n\"\n",
    "    \n",
    "    for framework_name, description in guidelines['frameworks'].items():\n",
    "        prompt += f\"{framework_name.upper().replace('_', ' ')}:\\n\"\n",
    "        prompt += f\"{description}\\n\\n\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "Extract ALL insights from the interview:\n",
    "- Pain points: Problems causing time waste, costs, uncertainty, frustration\n",
    "- Jobs-to-be-done: What they're trying to accomplish (functional + emotional goals)\n",
    "- Workarounds: Current hacks/solutions they've created\n",
    "- Desired outcomes: What success looks like to them\n",
    "- Behavioral signals: Implicit patterns revealing underlying needs\n",
    "- Mental models: How they conceptualize their work\n",
    "\n",
    "Always include exact quotes as evidence.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "system_prompt = build_system_prompt(guidelines)\n",
    "\n",
    "multi_insight_agent = Agent(\n",
    "    model='openai:gpt-4o-mini',\n",
    "    output_type=InterviewInsights,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(\"Agent created with frameworks from research guidelines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35f3bb-84aa-463f-9b49-694e5095229d",
   "metadata": {},
   "source": [
    "File loading helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf6e0909-a1e0-486b-9e36-802fc4c9d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loading ready\n"
     ]
    }
   ],
   "source": [
    "def load_transcript(filepath: str) -> str:\n",
    "    \"\"\"Load interview transcript from file\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "print(\"File loading ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db28339-98b1-43bb-97d9-53876c71ab7c",
   "metadata": {},
   "source": [
    "Load test files and run analysis with pre-defined privacy enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54f36bfb-6a44-452f-b684-b9993d84387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PII Detection Summary:\n",
      "------------------------------\n",
      "Emails                   0\n",
      "Phone Numbers            0\n",
      "Employee IDs             0\n",
      "Names                  131\n",
      "IBANs                    0\n",
      "API Tokens               0\n",
      "------------------------------\n",
      "TOTAL                  131\n",
      "\n",
      "PII removed from transcript\n",
      "Output validated - no PII detected\n"
     ]
    }
   ],
   "source": [
    "# Load \n",
    "transcript = load_transcript('data/interviews/mock_interview.txt')\n",
    "\n",
    "# Audit PII\n",
    "audit_pii_in_transcript(transcript, guidelines['privacy_enforcement'])\n",
    "\n",
    "# Remove PII\n",
    "clean_transcript = enforce_pii_removal(transcript, guidelines['privacy_enforcement'])\n",
    "\n",
    "print(\"\\nPII removed from transcript\")\n",
    "\n",
    "# Extract insights\n",
    "result = await multi_insight_agent.run(clean_transcript)\n",
    "insights = result.output\n",
    "\n",
    "# Validate output\n",
    "validate_no_pii(insights, guidelines['privacy_enforcement'])\n",
    "print(\"Output validated - no PII detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee0074-8fec-4bcc-8630-b62751b1391e",
   "metadata": {},
   "source": [
    "Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f53c73b1-4b12-4e97-8a61-5f00d21c170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PAIN POINTS:\n",
      "\n",
      "1. Inconsistency in API responses, with some endpoints returning arrays and others returning objects with metadata.\n",
      "   Impact: Adds friction and complexity, hindering effective onboarding of new developers.\n",
      "   Quote: [NAME] now, some endpoints return arrays, others wrap everything in an object with metadata. [NAME]’s small, but it adds friction.\n",
      "\n",
      "2. Lack of a real sandbox for testing, leading to potential issues when using production for tests.\n",
      "   Impact: Risk of polluting production data; increases uncertainty in testing.\n",
      "   Quote: [NAME] isn’t a real sandbox. [NAME] we either mock responses, which doesn’t feel realistic, or we test against production and hope for the best.\n",
      "\n",
      "3. Insufficient error messages, especially with pagination errors.\n",
      "   Impact: Wastes time and leads to frustration when troubleshooting API issues.\n",
      "   Quote: [NAME] kept getting 'invalid cursor.' I couldn’t tell if I formatted it wrong or if it expired or what. [NAME] error message didn’t explain.\n",
      "\n",
      "\n",
      "JOBS-TO-BE-DONE:\n",
      "\n",
      "1. Functional: Integrate API for custom report generation\n",
      "   Emotional: Feel competent and in control during the integration process\n",
      "   Context: While working on generating reports for clients using the transaction data from the API.\n",
      "\n",
      "2. Functional: Debug API responses and errors effectively\n",
      "   Emotional: Feel confident and efficient in resolving issues quickly\n",
      "   Context: When encountering unexpected API response behavior, such as pagination issues.\n",
      "\n",
      "\n",
      "WORKAROUNDS:\n",
      "\n",
      "1. Write little scripts to experiment with API requests and responses.\n",
      "   Why: To reduce guesswork and better understand how to format requests and what fields to use.\n",
      "   Cost: Takes additional time to write and test scripts.\n",
      "\n",
      "2. Search through old repositories for previous API usage examples.\n",
      "   Why: To fill in the gaps when documentation is unclear or fields are not self-explanatory.\n",
      "   Cost: Time-consuming to sift through past code bases.\n",
      "\n",
      "\n",
      "DESIRED OUTCOMES:\n",
      "\n",
      "1. A more consistent API design that reduces onboarding time for new developers.\n",
      "   Gap: Currently, multiple response formats create confusion and learning curves.\n",
      "\n",
      "2. Access to metrics such as latency and error rates to catch issues early.\n",
      "   Gap: No visibility into API performance until issues arise from logs or customer reports.\n",
      "\n",
      "\n",
      "BEHAVIORAL SIGNALS:\n",
      "\n",
      "1. Continually experimenting with scripts and searching old repos indicates a pattern of wanting to understand the API better.\n",
      "   Reveals: A high level of frustration with documentation and a need for more effective resources for integration.\n",
      "\n",
      "2. The shift from being a product developer to an 'API detective' shows how the API's issues affect their primary job.\n",
      "   Reveals: A significant amount of time and mental energy is diverted from core development work due to API-related issues.\n",
      "\n",
      "\n",
      "MENTAL MODELS:\n",
      "\n",
      "1. Considers the API as a plumbing system—necessary for operations but should remain unobtrusive.\n",
      "   Metaphor: It's like plumbing, delivering data but should be invisible and reliable.\n",
      "   Mismatch: When the API fails or requires extensive debugging, it disrupts their workflow significantly.\n",
      "\n",
      "2. Views API documentation as a secondary resource that requires hands-on experimentation to comprehend.\n",
      "   Metaphor: The documentation is akin to a manual that doesn’t cover the nuances of operation.\n",
      "   Mismatch: The real-world operation often doesn't align with what's described, leading to frequent guesswork.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPAIN POINTS:\")\n",
    "for i, pp in enumerate(insights.pain_points, 1):\n",
    "    print(f\"\\n{i}. {pp.description}\")\n",
    "    print(f\"   Impact: {pp.impact}\")\n",
    "    print(f\"   Quote: {pp.quote}\")\n",
    "\n",
    "print(\"\\n\\nJOBS-TO-BE-DONE:\")\n",
    "for i, job in enumerate(insights.jobs_to_be_done, 1):\n",
    "    print(f\"\\n{i}. Functional: {job.functional_job}\")\n",
    "    print(f\"   Emotional: {job.emotional_job}\")\n",
    "    print(f\"   Context: {job.context}\")\n",
    "\n",
    "print(\"\\n\\nWORKAROUNDS:\")\n",
    "for i, w in enumerate(insights.workarounds, 1):\n",
    "    print(f\"\\n{i}. {w.what_they_do}\")\n",
    "    print(f\"   Why: {w.why_needed}\")\n",
    "    print(f\"   Cost: {w.cost}\")\n",
    "\n",
    "print(\"\\n\\nDESIRED OUTCOMES:\")\n",
    "for i, outcome in enumerate(insights.desired_outcomes, 1):\n",
    "    print(f\"\\n{i}. {outcome.outcome}\")\n",
    "    print(f\"   Gap: {outcome.current_gap}\")\n",
    "\n",
    "print(\"\\n\\nBEHAVIORAL SIGNALS:\")\n",
    "for i, signal in enumerate(insights.behavioral_signals, 1):\n",
    "    print(f\"\\n{i}. {signal.observation}\")\n",
    "    print(f\"   Reveals: {signal.what_it_reveals}\")\n",
    "\n",
    "print(\"\\n\\nMENTAL MODELS:\")\n",
    "for i, model in enumerate(insights.mental_models, 1):\n",
    "    print(f\"\\n{i}. {model.description}\")\n",
    "    if model.metaphor_or_analogy:\n",
    "        print(f\"   Metaphor: {model.metaphor_or_analogy}\")\n",
    "    if model.mismatch_with_reality:\n",
    "        print(f\"   Mismatch: {model.mismatch_with_reality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0086297-6bd4-4742-a83b-56d3d6f8410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
